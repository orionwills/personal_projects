{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "from random import randint\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# default pandas decimal number display format\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data exploration\n",
    "import scipy.stats as stats\n",
    "\n",
    "# data modeling\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation(X_train, X_test, y_train, y_test):\n",
    "    if X_train.shape[0] == y_train.shape[0]:\n",
    "        print(\"X & y train rows ARE equal\")\n",
    "    else:\n",
    "        print(\"X & y train rows ARE NOT equal\")\n",
    "    if X_test.shape[0] == y_test.shape[0]:\n",
    "        print(\"X & y test rows ARE equal\")\n",
    "    else:\n",
    "        print(\"X & y test rows ARE NOT equal\")\n",
    "    if train.shape[1] == test.shape[1]:\n",
    "        print(\"Number of columns in train & test ARE equal\")\n",
    "    else:\n",
    "        print(\"Number of columns in train & test ARE NOT equal\")\n",
    "    train_split = train.shape[0] / (train.shape[0] + test.shape[0])\n",
    "    test_split = test.shape[0] / (train.shape[0] + test.shape[0])\n",
    "    print(\"Train Split: %.2f\" % train_split)\n",
    "    print(\"Test Split: %.2f\" % test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding and scaling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# train, test, split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data exploration\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "\n",
    "# data modeling\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "# usage example:\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(DF.data, iris.target)\n",
    "\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "# graph = graphviz.Source(dot_data) \n",
    "# graph.render('DF_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest neighbor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# data modeling example:\n",
    "# k_range = range(1, 20)\n",
    "# scores = []\n",
    "# for k in k_range:\n",
    "#     knn = KNeighborsClassifier(n_neighbors = k)\n",
    "#     knn.fit(X_train, y_train)\n",
    "#     scores.append(knn.score(X_test, y_test))\n",
    "# plt.figure()\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.scatter(k_range, scores)\n",
    "# plt.xticks([0,5,10,15,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VotingClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# usage example:\n",
    "# Training classifiers\n",
    "# clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "# clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "# clf3 = SVC(gamma=.1, kernel='rbf', probability=True)\n",
    "# eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2),\n",
    "#                                     ('svc', clf3)],\n",
    "#                         voting='soft', weights=[2, 1, 2])\n",
    "\n",
    "# clf1.fit(X, y)\n",
    "# clf2.fit(X, y)\n",
    "# clf3.fit(X, y)\n",
    "# eclf.fit(X, y)\n",
    "\n",
    "# print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "#      .format(clf1.score(X, y)))\n",
    "\n",
    "# print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "#      .format(clf2.score(X, y)))\n",
    "\n",
    "# print('Accuracy of SVC classifier on training set: {:.2f}'\n",
    "#      .format(clf3.score(X, y)))\n",
    "\n",
    "# print('Accuracy of a Voting Classifier using clf1, clf2, and clf3 on training set: {:.2f}'\n",
    "#      .format(eclf.score(X, y)))\n",
    "\n",
    "# plot decision boundaries\n",
    "# f, axarr = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "# for idx, clf, tt in zip(product([0, 1], [0, 1]),\n",
    "#                         [clf1, clf2, clf3, eclf],\n",
    "#                         ['Decision Tree (depth=4)', 'KNN (k=7)',\n",
    "#                          'Kernel SVM', 'Soft Voting']):\n",
    "\n",
    "#     Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.4)\n",
    "#     axarr[idx[0], idx[1]].scatter(X[:, 0], X[:, 1], c=y,\n",
    "#                                   s=20, edgecolor='k')\n",
    "#     axarr[idx[0], idx[1]].set_title(tt)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter columns and missing values\n",
    "def remove_columns(df, cols_to_remove):  \n",
    "    df = df.drop(columns=cols_to_remove)\n",
    "    return df\n",
    "\n",
    "def handle_missing_values(df, prop_required_column = .5, prop_required_row = .75):\n",
    "    threshold = int(round(prop_required_column*len(df.index),0))\n",
    "    df.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "    threshold = int(round(prop_required_row*len(df.columns),0))\n",
    "    df.dropna(axis=0, thresh=threshold, inplace=True)\n",
    "    return df\n",
    "\n",
    "def data_prep(df, cols_to_remove=[], prop_required_column=.5, prop_required_row=.75):\n",
    "    df = remove_columns(df, cols_to_remove)\n",
    "    df = handle_missing_values(df, prop_required_column, prop_required_row)\n",
    "    return df\n",
    "\n",
    "# detect and remove outliers\n",
    "def get_upper_outliers(s, k):\n",
    "    '''\n",
    "    Given a series and a cutoff value, k, returns the upper outliers for the\n",
    "    series.\n",
    "\n",
    "    The values returned will be either 0 (if the point is not an outlier), or a\n",
    "    number that indicates how far away from the upper bound the observation is.\n",
    "    '''\n",
    "    q1, q3 = s.quantile([.25, .75])\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + k * iqr\n",
    "    return s.apply(lambda x: max([x - upper_bound, 0]))\n",
    "\n",
    "def add_upper_outlier_columns(df, k):\n",
    "    '''\n",
    "    Add a column with the suffix _outliers for all the numeric columns\n",
    "    in the given dataframe.\n",
    "    '''\n",
    "    # outlier_cols = {col + '_outliers': get_upper_outliers(df[col], k)\n",
    "    #                 for col in df.select_dtypes('number')}\n",
    "    # return df.assign(**outlier_cols)\n",
    "\n",
    "    for col in df.select_dtypes('number'):\n",
    "        df[col + '_outliers'] = get_upper_outliers(df[col], k)\n",
    "\n",
    "    return df\n",
    "\n",
    "# view outliers\n",
    "# outlier_cols = [col for col in df if col.endswith('_outliers')]\n",
    "# for col in outlier_cols:\n",
    "#     print('~~~\\n' + col)\n",
    "#     data = df[col][df[col] > 0]\n",
    "#     print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing\n",
    "from matplotlib import cm\n",
    "\n",
    "# Modeling\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.cluster.vq import kmeans2, whiten\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 1 of visualization of clusters\n",
    "# for i, (title, kmeans) in enumerate(estimators):\n",
    "#     # fit the model\n",
    "#     kmeans.fit(X)\n",
    "\n",
    "#     labels = kmeans.labels_\n",
    "\n",
    "#     # setup the 3d plot\n",
    "#     fignum = i + 1\n",
    "#     fig = plt.figure(fignum, figsize=(4, 3))\n",
    "#     ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "#     # plot the points\n",
    "#     ax.scatter(X.petal_width, X.sepal_length, X.petal_length,\n",
    "#                c=labels.astype(np.float), edgecolor='k')\n",
    "\n",
    "#     ax.w_xaxis.set_ticklabels([])\n",
    "#     ax.w_yaxis.set_ticklabels([])\n",
    "#     ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "#     ax.set_xlabel('Petal Width')\n",
    "#     ax.set_ylabel('Sepal Length')\n",
    "#     ax.set_zlabel('Petal Length')\n",
    "\n",
    "#     ax.set_title(title)\n",
    "#     ax.dist = 12\n",
    "\n",
    "# example 2 of visualization of clusters\n",
    "# fig = plt.figure(fignum, figsize=(4, 3))\n",
    "# ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "# # add species names\n",
    "# for species in iris.species_name.unique():\n",
    "#     df = iris[iris.species_name == species]\n",
    "#     x = df.petal_width.mean()\n",
    "#     y = df.sepal_length.mean()\n",
    "#     z = df.petal_length.mean() + 2\n",
    "\n",
    "#     ax.text3D(x, y, z, species,\n",
    "#               horizontalalignment='center',\n",
    "#               bbox=dict(alpha=.2, edgecolor='w', facecolor='w'))\n",
    "\n",
    "# # add the actual data points\n",
    "# ax.scatter(X.petal_width, X.sepal_length, X.petal_length, c=iris.species_id, edgecolor='k')\n",
    "\n",
    "# ax.w_xaxis.set_ticklabels([])\n",
    "# ax.w_yaxis.set_ticklabels([])\n",
    "# ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "# ax.set_xlabel('Petal width')\n",
    "# ax.set_ylabel('Sepal length')\n",
    "# ax.set_zlabel('Petal length')\n",
    "# ax.set_title('Actual Species Clusters')\n",
    "# ax.dist = 12\n",
    "\n",
    "# fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.vq import kmeans2, whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hierarchical clustering libraries\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy dendogram\n",
    "# Annotating the distances inside the dendrogram\n",
    "# def fancy_dendrogram(*args, **kwargs):\n",
    "#     max_d = kwargs.pop('max_d', None)\n",
    "#     if max_d and 'color_threshold' not in kwargs:\n",
    "#         kwargs['color_threshold'] = max_d\n",
    "#     annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "#     ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "#     if not kwargs.get('no_plot', False):\n",
    "#         plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "#         plt.xlabel('sample index or (cluster size)')\n",
    "#         plt.ylabel('distance')\n",
    "#         for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "#             x = 0.5 * sum(i[1:3])\n",
    "#             y = d[1]\n",
    "#             if y > annotate_above:\n",
    "#                 plt.plot(x, y, 'o', c=c)\n",
    "#                 plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
    "#                              textcoords='offset points',\n",
    "#                              va='top', ha='center')\n",
    "#         if max_d:\n",
    "#             plt.axhline(y=max_d, c='k')\n",
    "#     return ddata\n",
    "\n",
    "# fancy_dendrogram(\n",
    "#     Z,\n",
    "#     truncate_mode='lastp',\n",
    "#     p=12,\n",
    "#     leaf_rotation=90.,\n",
    "#     leaf_font_size=12.,\n",
    "#     show_contracted=True,\n",
    "#     annotate_above=10,  # useful in small plots so annotations don't overlap\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametric Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful plot and evaluate functions\n",
    "# def plot_data_and_predictions(predictions, label):\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "\n",
    "#     plt.plot(train,label='Train')\n",
    "#     plt.plot(test, label='Test')\n",
    "#     plt.plot(predictions, label=label, linewidth=5)\n",
    "\n",
    "#     plt.legend(loc='best')\n",
    "#     plt.show()\n",
    "\n",
    "# def evaluate(actual, predictions, output=True):\n",
    "#     mse = metrics.mean_squared_error(actual, predictions)\n",
    "#     rmse = math.sqrt(mse)\n",
    "\n",
    "#     if output:\n",
    "#         print('MSE:  {}'.format(mse))\n",
    "#         print('RMSE: {}'.format(rmse))\n",
    "#     else:\n",
    "#         return mse, rmse    \n",
    "\n",
    "# def plot_and_eval(predictions, actual, metric_fmt='{:.2f}', linewidth=4):\n",
    "#     if type(predictions) is not list:\n",
    "#         predictions = [predictions]\n",
    "\n",
    "#     plt.figure(figsize=(16, 8))\n",
    "#     plt.plot(train,label='Train')\n",
    "#     plt.plot(test, label='Test')\n",
    "\n",
    "#     for yhat in predictions:\n",
    "#         mse, rmse = evaluate(actual, yhat, output=False)        \n",
    "#         label = f'{yhat.name}'\n",
    "#         if len(predictions) > 1:\n",
    "#             label = f'{label} -- MSE: {metric_fmt} RMSE: {metric_fmt}'.format(mse, rmse)\n",
    "#         plt.plot(yhat, label=label, linewidth=linewidth)\n",
    "\n",
    "#     if len(predictions) == 1:\n",
    "#         label = f'{label} -- MSE: {metric_fmt} RMSE: {metric_fmt}'.format(mse, rmse)\n",
    "#         plt.title(label)\n",
    "\n",
    "#     plt.legend(loc='best')\n",
    "#     plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation, performance_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "from sklearn import metrics\n",
    "from random import randint\n",
    "from matplotlib import style\n",
    "from numpy import linspace, loadtxt, ones, convolve\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing EMA\n",
    "# Using Pandas to calculate a 2 hour span EMA. \n",
    "# adjust=False specifies that we are interested in the \n",
    "# recursive calculation mode.\n",
    "# ema_short = train.ewm(span=12, adjust=False).mean()\n",
    "# ema_short[0:3]\n",
    "\n",
    "# ema_long = train.ewm(span=span, adjust=False).mean()\n",
    "# ema_long[0:3]\n",
    "\n",
    "# span = 24\n",
    "# ema_long = train.ewm(span=span, adjust=False).mean()\n",
    "# midband = ema_long[-1]\n",
    "# ub = midband + ema_long[-24:-1].std()*3\n",
    "# lb = midband - ema_long[-24:-1].std()*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "from sklearn import metrics\n",
    "from random import randint\n",
    "from matplotlib import style\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful function to plot clf\n",
    "def plot_clf(x, y, x_min, x_max, y_min, y_max, x_label, y_label):\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 25), np.linspace(y_min, y_max, 25))\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.title(\"IsolationForest\")\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\n",
    "\n",
    "    b1 = plt.scatter(train[x], train[y],\n",
    "                     c='white',\n",
    "                     s=20, \n",
    "                     edgecolor='k')\n",
    "    b2 = plt.scatter(test[x], test[y], \n",
    "                     c='green',\n",
    "                     s=20, \n",
    "                     edgecolor='k')\n",
    "    b3 = plt.scatter(outlier[x], outlier[y],\n",
    "                    c='red',\n",
    "                    s=20,\n",
    "                    edgecolor='k')\n",
    "    plt.axis('tight')\n",
    "    plt.xlim((x_min, x_max))\n",
    "    plt.ylim((y_min, y_max))\n",
    "    plt.legend([b1, b2, b3],\n",
    "               [\"half1\",\n",
    "                \"half2\",\n",
    "               \"post_cohort\"],\n",
    "               loc=\"best\")\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# example usage:\n",
    "# plot_clf('days_normalized', 'page_viewed', 0, 400,\\\n",
    "#          0, 275, 'Days', 'Pages Viewed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
